{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 438
    },
    "id": "S1t5-cjhja30",
    "outputId": "540e7a09-91a3-47b0-ef80-939dc75e8a5f"
   },
   "outputs": [],
   "source": [
    "#Main imports\n",
    "import pytest\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "\n",
    "from typing import Tuple\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import nn, optim\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import precision_score, recall_score, roc_auc_score\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.utils._testing import ignore_warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "\n",
    "import os.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add files to sys \n",
    "import os, sys\n",
    "sys.path.append(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DECAF Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tests.utils import load_adult\n",
    "from tests.test_decaf import test_run_experiments\n",
    "\n",
    "X, y, df = load_adult()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\space\\anaconda3\\envs\\factai\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "C:\\Users\\space\\anaconda3\\envs\\factai\\lib\\site-packages\\pytorch_lightning\\trainer\\configuration_validator.py:99: UserWarning: you passed in a val_dataloader but have no validation_step. Skipping val loop\n",
      "  rank_zero_warn(f\"you passed in a {loader_name} but have no {step_name}. Skipping {stage} loop\")\n",
      "\n",
      "  | Name          | Type             | Params\n",
      "---------------------------------------------------\n",
      "0 | generator     | Generator_causal | 128 K \n",
      "1 | discriminator | Discriminator    | 43.4 K\n",
      "---------------------------------------------------\n",
      "171 K     Trainable params\n",
      "196       Non-trainable params\n",
      "171 K     Total params\n",
      "0.686     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baseline scores 0.8771004942339374 0.9400547364703805 0.7713060043566607\n",
      "Initialised adjacency matrix as parsed:\n",
      " Parameter containing:\n",
      "tensor([[0., 1., 0., 1., 0., 1., 1., 0., 0., 0., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 1., 0., 0., 1., 1., 0., 0., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 1., 0., 1., 1., 0., 0., 0., 0., 0., 1., 0.],\n",
      "        [0., 1., 0., 1., 0., 1., 1., 1., 0., 0., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 1., 0., 1., 0., 1., 0., 0., 0., 0., 1., 0.]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\space\\anaconda3\\envs\\factai\\lib\\site-packages\\pytorch_lightning\\trainer\\data_loading.py:106: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  f\"The dataloader, {name}, does not have many workers which may be a bottleneck.\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12aedcbbf4f04edd884e46bf34588cc6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: -1it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4.35769320e-01 3.29245928e-08 1.41432852e-01 ... 5.98687939e-06\n",
      "  4.58957881e-01 5.24330745e-10]\n",
      " [4.25009340e-01 1.68820694e-10 1.65413752e-01 ... 7.41137512e-07\n",
      "  4.73381132e-01 1.29614534e-07]\n",
      " [1.21706419e-01 4.57931459e-01 2.29698718e-01 ... 5.53579768e-04\n",
      "  4.58740830e-01 2.02330062e-03]\n",
      " ...\n",
      " [3.93053889e-01 6.31911278e-01 2.39255965e-01 ... 1.07838621e-03\n",
      "  4.63055521e-01 3.52310570e-10]\n",
      " [4.46874164e-02 1.33586378e-10 1.42350972e-01 ... 7.38972332e-04\n",
      "  4.72407132e-01 7.09834918e-02]\n",
      " [4.35627908e-01 4.49071944e-01 1.03305906e-01 ... 5.95281762e-08\n",
      "  4.60556477e-01 2.76018138e-04]]\n",
      "Getting metrics...\n",
      "0        1.000000\n",
      "1        1.000000\n",
      "2        1.000000\n",
      "3        1.000000\n",
      "4        1.000000\n",
      "           ...   \n",
      "30157    1.000000\n",
      "30158    0.000517\n",
      "30159    1.000000\n",
      "30160    1.000000\n",
      "30161    0.000484\n",
      "Name: sex, Length: 30162, dtype: float32\n",
      "Statistics for dataset for mode: ftu\n",
      "Precision: 0.9378238341968912\n",
      "Recall: 0.7941928345224922\n",
      "AUROC: 0.722545443317406\n",
      "FTU: 0.28519328956965717\n",
      "DP: 0.3367075119872137\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-1ce790cbc59f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mX_synth\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_synth\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_run_experiments\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'ftu'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object is not iterable"
     ]
    }
   ],
   "source": [
    "test_run_experiments(X, y, df, 'ftu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "C:\\Users\\space\\anaconda3\\envs\\factai\\lib\\site-packages\\pytorch_lightning\\trainer\\configuration_validator.py:99: UserWarning: you passed in a val_dataloader but have no validation_step. Skipping val loop\n",
      "  rank_zero_warn(f\"you passed in a {loader_name} but have no {step_name}. Skipping {stage} loop\")\n",
      "\n",
      "  | Name          | Type             | Params\n",
      "---------------------------------------------------\n",
      "0 | generator     | Generator_causal | 128 K \n",
      "1 | discriminator | Discriminator    | 43.4 K\n",
      "---------------------------------------------------\n",
      "171 K     Trainable params\n",
      "196       Non-trainable params\n",
      "171 K     Total params\n",
      "0.686     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baseline scores 0.887231223015432 0.9161737441511433 0.7824075966360404\n",
      "Initialised adjacency matrix as parsed:\n",
      " Parameter containing:\n",
      "tensor([[0., 1., 0., 1., 0., 1., 1., 0., 0., 0., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 1., 0., 0., 1., 1., 0., 0., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 1., 0., 1., 1., 0., 0., 0., 0., 0., 1., 0.],\n",
      "        [0., 1., 0., 1., 0., 1., 1., 1., 0., 0., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 1., 0., 1., 0., 1., 0., 0., 0., 0., 1., 0.]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\space\\anaconda3\\envs\\factai\\lib\\site-packages\\pytorch_lightning\\trainer\\data_loading.py:106: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  f\"The dataloader, {name}, does not have many workers which may be a bottleneck.\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4ec4978d4004423ae79bfc5ab286ec2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: -1it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3.7089515e-01 9.1037269e-05 3.4088053e-02 ... 1.7860682e-05\n",
      "  4.4294679e-01 1.7703438e-07]\n",
      " [1.3247526e-01 2.4755055e-01 1.6436018e-01 ... 7.4902329e-07\n",
      "  4.2556778e-01 8.0773279e-06]\n",
      " [3.6864707e-01 6.8531078e-01 7.8647874e-02 ... 4.3885182e-03\n",
      "  3.7024042e-01 5.2202722e-07]\n",
      " ...\n",
      " [3.7543008e-01 2.8371427e-04 1.6452190e-01 ... 9.5931694e-02\n",
      "  4.2484123e-01 2.8253990e-07]\n",
      " [2.4851978e-02 2.0432137e-06 1.2642306e-01 ... 1.4537807e-07\n",
      "  4.2815462e-01 2.8388336e-02]\n",
      " [2.3136160e-01 6.3227927e-03 8.9605026e-02 ... 3.2656683e-06\n",
      "  4.3474653e-01 1.6616696e-01]]\n",
      "Getting metrics...\n",
      "0        0.000176\n",
      "1        1.000000\n",
      "2        0.000163\n",
      "3        1.000000\n",
      "4        0.977284\n",
      "           ...   \n",
      "30157    1.000000\n",
      "30158    1.000000\n",
      "30159    0.939802\n",
      "30160    1.000000\n",
      "30161    0.999971\n",
      "Name: sex, Length: 30162, dtype: float32\n",
      "Statistics for dataset for mode: dp\n",
      "Precision: 0.9620091702002965\n",
      "Recall: 0.9682176190971861\n",
      "AUROC: 0.5732214120840143\n",
      "FTU: 0.045951859956236324\n",
      "DP: 0.055407565263718594\n"
     ]
    }
   ],
   "source": [
    "test_run_experiments(X, y, df, 'dp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "C:\\Users\\space\\anaconda3\\envs\\factai\\lib\\site-packages\\pytorch_lightning\\trainer\\configuration_validator.py:99: UserWarning: you passed in a val_dataloader but have no validation_step. Skipping val loop\n",
      "  rank_zero_warn(f\"you passed in a {loader_name} but have no {step_name}. Skipping {stage} loop\")\n",
      "\n",
      "  | Name          | Type             | Params\n",
      "---------------------------------------------------\n",
      "0 | generator     | Generator_causal | 128 K \n",
      "1 | discriminator | Discriminator    | 43.4 K\n",
      "---------------------------------------------------\n",
      "171 K     Trainable params\n",
      "196       Non-trainable params\n",
      "171 K     Total params\n",
      "0.686     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baseline scores 0.8823899371069183 0.9289750154498102 0.7776867618538342\n",
      "Initialised adjacency matrix as parsed:\n",
      " Parameter containing:\n",
      "tensor([[0., 1., 0., 1., 0., 1., 1., 0., 0., 0., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 1., 0., 0., 1., 1., 0., 0., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 1., 0., 1., 1., 0., 0., 0., 0., 0., 1., 0.],\n",
      "        [0., 1., 0., 1., 0., 1., 1., 1., 0., 0., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 1., 0., 1., 0., 1., 0., 0., 0., 0., 1., 0.]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\space\\anaconda3\\envs\\factai\\lib\\site-packages\\pytorch_lightning\\trainer\\data_loading.py:106: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  f\"The dataloader, {name}, does not have many workers which may be a bottleneck.\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90537e6c884f42ba975d6b9730cf5e88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: -1it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4.1337845e-01 8.4799504e-01 2.5292290e-02 ... 2.7983971e-08\n",
      "  4.8152587e-01 5.8112843e-08]\n",
      " [4.2829132e-01 7.4742770e-01 7.1436688e-02 ... 1.2096819e-02\n",
      "  4.7435984e-01 2.9705085e-03]\n",
      " [4.0756512e-01 3.6773622e-09 1.8982632e-01 ... 1.4494367e-05\n",
      "  4.7812492e-01 1.9173013e-08]\n",
      " ...\n",
      " [4.5078513e-01 1.9508073e-01 1.7670873e-01 ... 3.1376153e-02\n",
      "  4.7585717e-01 6.6416787e-06]\n",
      " [4.0702873e-01 1.0020887e-06 9.2037201e-02 ... 1.6135353e-08\n",
      "  4.7107500e-01 1.0830268e-02]\n",
      " [4.1281366e-01 1.6692541e-11 1.2309223e-01 ... 3.5746716e-06\n",
      "  4.8081869e-01 2.8868322e-04]]\n",
      "Getting metrics...\n",
      "0        0.000414\n",
      "1        0.000308\n",
      "2        1.000000\n",
      "3        1.000000\n",
      "4        1.000000\n",
      "           ...   \n",
      "30157    0.000422\n",
      "30158    1.000000\n",
      "30159    1.000000\n",
      "30160    0.999999\n",
      "30161    0.000247\n",
      "Name: sex, Length: 30162, dtype: float32\n",
      "Statistics for dataset for mode: cf\n",
      "Precision: 0.8317031928649581\n",
      "Recall: 0.9999601371282787\n",
      "AUROC: 0.49998006856413935\n",
      "FTU: 0.0043432133147669255\n",
      "DP: 0.00013319126265320946\n"
     ]
    }
   ],
   "source": [
    "test_run_experiments(X, y, df, 'cf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CTGAN - COMPARISON TO DECAF\n",
    "This model will automatically load pretrained models and calculate the appropriate metrics.\n",
    "It will also print the progress. (This will still take some time!) These tests will output the approximate metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: THIS WILL TAKE SIGNIFICANT TIME EVEN WITH SAVED MODELS AS THE SAMPLING TAKES TIME TOO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 508
    },
    "id": "QOa1glz3wCe-",
    "outputId": "696b2f1b-b3e2-48d9-9f58-cf11be291cb9"
   },
   "outputs": [],
   "source": [
    "from table_evaluator import TableEvaluator\n",
    "from ctgan import CTGANSynthesizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ./CTGAN/FACT_GAN.ipynb\n",
    "\n",
    "# Run the experiments with the three privacy definitions\n",
    "run_experiment_CTGAN('FTU')\n",
    "run_experiment_CTGAN('CF') \n",
    "run_experiment_CTGAN('DP')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "FACT GAN",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
